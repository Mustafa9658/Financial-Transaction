{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gizAIaczlnqZ",
        "outputId": "dcabceff-f8bb-4ba1-aad1-684ad090b589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_6rBYiLElvaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a60b8f-4b70-42a9-c831-476a9e83015c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Asset       1.00      1.00      1.00       436\n",
            "      Equity       1.00      1.00      1.00       507\n",
            "     Expense       1.00      1.00      1.00       514\n",
            "   Liability       1.00      1.00      1.00       477\n",
            "Other Income       1.00      1.00      1.00        11\n",
            "     Revenue       1.00      1.00      1.00       555\n",
            "\n",
            "   micro avg       1.00      1.00      1.00      2500\n",
            "   macro avg       1.00      1.00      1.00      2500\n",
            "weighted avg       1.00      1.00      1.00      2500\n",
            " samples avg       1.00      1.00      1.00      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the combined dataset from the CSV file\n",
        "data = pd.read_csv(\"/content/merged_dataset.csv\")\n",
        "\n",
        "# Select relevant columns for model training\n",
        "X = data['Description']  # Features\n",
        "y = data['Category']  # Target\n",
        "\n",
        "# Convert the target variable 'Category' to binary labels\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_binary = mlb.fit_transform(y.str.split(','))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "\n",
        "# Lemmatization function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train_lemmatized = X_train.apply(lambda x: lemmatize_text(x.lower()))\n",
        "X_test_lemmatized = X_test.apply(lambda x: lemmatize_text(x.lower()))\n",
        "\n",
        "# Transform text data into numerical features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_lemmatized)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test_lemmatized)\n",
        "\n",
        "# Define Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YFPBFlTl8mz",
        "outputId": "ec41495a-81b3-4c1d-f2a8-7725b1f5ebff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter description (or 'exit' to quit): Capital invested by a new partner\n",
            "Predicted categories: [('Equity',)]\n",
            "Enter description (or 'exit' to quit): exit\n",
            "Exiting program.\n"
          ]
        }
      ],
      "source": [
        "# Preprocess input description\n",
        "def preprocess_input(description):\n",
        "    # Lemmatize and lower the input description\n",
        "    processed_description = lemmatize_text(description.lower())\n",
        "    return processed_description\n",
        "\n",
        "# Predict categories for input description\n",
        "def predict_categories(description):\n",
        "    # Preprocess input description\n",
        "    processed_description = preprocess_input(description)\n",
        "\n",
        "    # Transform input description using TF-IDF vectorizer\n",
        "    description_tfidf = tfidf_vectorizer.transform([processed_description])\n",
        "\n",
        "    # Predict categories\n",
        "    predicted_categories = rf_classifier.predict(description_tfidf)\n",
        "\n",
        "    # Decode predicted labels\n",
        "    predicted_categories_decoded = mlb.inverse_transform(predicted_categories)\n",
        "\n",
        "    return predicted_categories_decoded\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    while True:\n",
        "        # Input description\n",
        "        description = input(\"Enter description (or 'exit' to quit): \")\n",
        "\n",
        "        # Check for exit condition\n",
        "        if description.lower() == 'exit':\n",
        "            print(\"Exiting program.\")\n",
        "            break\n",
        "\n",
        "        # Predict categories\n",
        "        predicted_categories = predict_categories(description)\n",
        "\n",
        "        # Display predicted categories\n",
        "        print(\"Predicted categories:\", predicted_categories)\n",
        "\n",
        "# Run main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuSahrZzmB6W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}